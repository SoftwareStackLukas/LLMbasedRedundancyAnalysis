# RedundancyAndConflictAnalysis

## Goal Definition
    - Main Part and Benefit analyse
    - Main Part: alles was nicht der Benefit ist
    - Benefit: the outcome of the action

### Steps
    - [] Mal eine Redundanzen aus den Daten von Amir raussuchen - Rausnehemen dann auch einfach die Daten dann aus den Analysen raus | schauen ob es besser wird mit dem oder neue beispiel 
    - [] Create time protocoll of how long is needed to analyse all in average
    - [] Create a token protokoll to check how long the single tokens are
    - [X] Hauptteil definieren
    - [X] Analyse von Hauptteil und Benefit gleichzeitig
    - [X] JSON format dafür vorbereiten
    - [X] Beispiele der JSON Datei überarbeiten
    - [] Analyse der Redundanzen gleichzeitig
    - [] Den Studenten fragen, wie das finale Format für die Redundanzen aussieht
    - [] Einmal nur die User Stories übergeben und einmal die User Stories mit den Annotations übergeben (Richtiger teil und nicht den Offset) (Das Delta bestimmen, was besser funktioniert)
    - [] First analyse the g03 dataset
    - [] Play with the parameterization of the model tempruature context etc.

    --> Seperate the User Storys. All for "so that" is the main part and aftwards is the benefit. Grammatikalisch anuseinander ziehen wobei der Nebensatz der benefit ist.  


### Libaries to look inside
    - [] LongChain
    - [] Multi Agent suppport (find a libary)
    - [] Use word embeddings
    - [] Vector Database for User Story Clustering
    - [] Redundant requierments can be clustered together 
    - [] Create an interactive application to convert user stories to Henshin as vice versa


### Use
    - With local .venv
    - VSCode
    - jupyter notebook

### Use full links
    - https://dylancastillo.co/clustering-documents-with-openai-langchain-hdbscan/ (Simple Clusterin with just Word Embeddings and k-meas algorithm)
    - https://github.com/daniel-furman/awesome-chatgpt-prompts-clustering (Simpler Clustering)
    - https://pytorch.org/ (advanced machine learning libary)
    - https://platform.openai.com/tokenizer Tokenizer for chatgpt